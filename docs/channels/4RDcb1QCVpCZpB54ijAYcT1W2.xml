<?xml version="1.0" encoding="utf-8"?><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Recent Discussions</title><link>https://planet.crystal-lang.org/</link><description></description><item><title>Kemal now uses a LRU Cache for Faster Routing Performance</title><link>https://old.reddit.com/r/crystal_programming/comments/1olhfag/kemal_now_uses_a_lru_cache_for_faster_routing/</link><author>/u/sdogruyol</author><category>community</category><pubDate>Sat, 1 Nov 2025 07:04:05 +0000</pubDate><source url="https://old.reddit.com/r/crystal_programming/">r/crystal_programming</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Annother Spinoff Shard: ralsina/rate_limiter</title><link>https://forum.crystal-lang.org/t/annother-spinoff-shard-ralsina-rate-limiter/8525</link><author>ralsina</author><category>community</category><pubDate>Fri, 31 Oct 2025 22:19:19 +0000</pubDate><source url="https://forum.crystal-lang.org/latest">Forum</source><content:encoded><![CDATA[I am sorry, I know I create a lot of topics all at once, but it happens when I actually have some time to work on my projects Basically, it’s a generic in-memory sliding window composible rate limiter. Usage looks like this:# Per user rate limiting
user_limiter = RateLimiter.new(50, 3600)  # 50 requests per hour per user

# Per IP rate limiting
ip_limiter = RateLimiter.new(200, 3600)  # 200 requests per hour per IP

# Per endpoint rate limiting
endpoint_limiter = RateLimiter.new(20, 60)  # 20 requests per minute per endpoint

# Per user + endpoint rate limiting
user_endpoint_limiter = RateLimiter.new(10, 60)  # 10 requests per minute per user+endpoint

# Check request (example: user trying to access API)
username = "alice"
ip = "10.0.0.1"
endpoint = "/api/create_note"

# Check all applicable rate limits
limits = [
  user_limiter.allow?(username),
  ip_limiter.allow?(ip),
  endpoint_limiter.allow?(endpoint),
  user_endpoint_limiter.allow?("#{username}::#{endpoint}")
]

if limits.any?
  # Request is allowed by all rate limiters
  process_request(username, ip, endpoint)
else
  # Request exceeds at least one rate limit
  render_error("Rate limit exceeded")
end
]]></content:encoded></item><item><title>Some performance testing</title><link>https://forum.crystal-lang.org/t/some-performance-testing/8524</link><author>ralsina</author><category>community</category><pubDate>Fri, 31 Oct 2025 20:04:30 +0000</pubDate><source url="https://forum.crystal-lang.org/latest">Forum</source><content:encoded><![CDATA[As I worked on ToCry I got curious about how well it performed.It was  built with performance as the main goal. In fact it’s sort of guaranteed not to be the fastest way to do things. It uses sepia as data storage, which is the opposite of efficient, and I implemented it .On the other hand, the best thing was to just write some scripts and measure things!Turns out … it’s pretty fast? It can have about 20 simultaneous users and 300 RPS on a Pi 4 with 4GB of RAM, and industry standard says that equates to about 200 users.200 users? On an old SBC! This is not scientific. What a “realistic” load is needs to be discovered by having actual users :-)]]></content:encoded></item><item><title>Second fiber does not complete</title><link>https://forum.crystal-lang.org/t/second-fiber-does-not-complete/8523</link><author>axd99</author><category>community</category><pubDate>Fri, 31 Oct 2025 16:49:59 +0000</pubDate><source url="https://forum.crystal-lang.org/latest">Forum</source><content:encoded><![CDATA[Hi, I am experimenting with crystal’s fibers and to test with a buffered channel I wrote this:# generate a list of file names.
# This is the data source.
list = [] of String
(1..4).each do |i|
  list << "file#{i}"
end

# provides communication between the producing fiber and the
# consuming one.
ch = Channel(String).new(3)

# fiber1
# this fiber loads the data into the channel
# This is the producer.
spawn do
  puts "--- Entering fiber1"
  list.each do |val|
    puts "fiber1, before send #{val}"
    ch.send val
    puts "fiber1, after send #{val}"
  end
  puts "--- Exiting fiber1"
end

# fiber2
# this fiber empties the channel
# This is the consumer.
spawn do
  puts "---- Entering fiber 2"
  while val2 = ch.receive
    puts "Received: #{val2}"
  end
  puts "---------------------"   # The code does not get to here
  puts "---- Exiting fiber2"
  puts "---------------------"
end

puts "Starting...\n"

# Start the fibers
Fiber.yield

# When the control gets back here all data has been exhausted.
puts "Goodbye!!!"

# shouldn't either of these 2 restart fiber2?
Fiber.yield
ch.close 
p ch.closed?


Now, when I run the above, all data is produced and consumed as expected.
However the ‘---- Exiting Fiber 2’ never executed.$ crystal list-files.cr
Starting...
--- Entering fiber1
fiber1, before send file1
fiber1, after send file1
fiber1, before send file2
fiber1, after send file2
fiber1, before send file3
fiber1, after send file3
fiber1, before send file4
---- Entering fiber 2
Received: file1
Received: file2
Received: file3
Received: file4
fiber1, after send file4
--- Exiting fiber1
Goodbye!!!
true
Any pointer would be most welcome.
Many thanks.]]></content:encoded></item><item><title>Wanna do an MCP? Try this :-)</title><link>https://forum.crystal-lang.org/t/wanna-do-an-mcp-try-this/8520</link><author>ralsina</author><category>community</category><pubDate>Wed, 29 Oct 2025 19:46:53 +0000</pubDate><source url="https://forum.crystal-lang.org/latest">Forum</source><content:encoded><![CDATA[MCP is a mechanism to expose things to AI agents.Turns out it’s super easy to do, and it gives you some amazing leverage for tools! For example, I gave my kanban board a MCP server and now I can just say “move the note “whatever” to done” and it works ;-)It supports stdio MCP servers (nice way to expose a CLI tool to AI agents) and web MCP servers (with kemal at least)Here is a FULL example of a MCP with a single tool, in stdio mode:require "mcp"

# A simple tool that returns the answer to any question
class AnswerTool < MCP::AbstractTool
  @@tool_name = "get_answer"
  @@tool_description = "Returns 42 as the answer to any question you ask"
  @@tool_input_schema = {
    "type"       => "object",
    "properties" => {
      "question" => {
        "type"        => "string",
        "description" => "The question you want answered",
      },
    },
    "required" => ["question"],
  }.to_json

  def invoke(params : Hash(String, JSON::Any), env : HTTP::Server::Context? = nil)
    question = params["question"]?.try(&.as_s) || "unknown question"
    {
      "answer"   => 42,
      "question" => question,
    }
  end
end

# Start the stdio server - that's it! One line and you have a complete MCP server.
MCP::StdioHandler.start_server
Have fun and let me know if something is not ergnomic, I am trying to make this as boilerplate-free as possible.11 posts - 5 participants]]></content:encoded></item><item><title>Airsailer - open source Cloud orchestrator in Crystal</title><link>https://forum.crystal-lang.org/t/airsailer-open-source-cloud-orchestrator-in-crystal/8516</link><author>paulocoghi</author><category>community</category><pubDate>Wed, 29 Oct 2025 09:45:44 +0000</pubDate><source url="https://forum.crystal-lang.org/latest">Forum</source><content:encoded><![CDATA[Missed you all during my cancer treatment, and I’m finally cancer-free!I’m back full-time at my cloud computing startup, and going fully open source (MIT license) for the entire platform.LXC (Linux/system containers) for bare-metal performance, no VM overhead (PoC working)elastic bare-metal hardware resources that can be changed without rebootelastic LVM storage with thin-provisioning (manually handled today)routing for local networks + WireGuard for clusters (manually handled today)Homogeneous deployment as the strategy for automatic horizontal scaling and load-balancing (will be on a future release with PaaS automation)automatic proxy + SSL for apps, no need for 1 public IP per app (proxy lib temporarily made in JS because of acme-client lib) IaaS+PaaS with 20% of features that cover 80% of cloud demand.I’m refactoring and I will release soon at github.com/airsailer/airsailer. Since I sustain my family only through this work, I expect to release a new production version soon.Happy to talk to you again. ]]></content:encoded></item></channel></rss>