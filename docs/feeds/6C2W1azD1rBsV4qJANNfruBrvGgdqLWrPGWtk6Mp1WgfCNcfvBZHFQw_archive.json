{"id":"6C2W1azD1rBsV4qJANNfruBrvGgdqLWrPGWtk6Mp1WgfCNcfvBZHFQw","title":"The System Design Newsletter","displayTitle":"Dev - System Design Newsletter","url":"https://newsletter.systemdesign.one/feed","feedLink":"https://newsletter.systemdesign.one/","isQuery":false,"isEmpty":false,"isHidden":false,"itemCount":3,"items":[{"title":"Concurrency Is Not Parallelism üî•","url":"https://newsletter.systemdesign.one/p/concurrency-is-not-parallelism","date":1750247172,"author":"Neo Kim","guid":121,"unread":true,"content":"<p>Get my system design playbook for FREE on newsletter signup:</p><p><em>This post outlines the differences between concurrency and parallelism. You will find references at the bottom of this page if you want to go deeper.</em></p><p>Once upon a time, computers had a single CPU and could run only one task at a time.</p><p>Still it completed tasks faster than humans.</p><p>Yet the system wasted CPU time waiting for input-output () responses, such as keyboard input. </p><p>And the system became slow and non-responsive as the number of tasks grew.</p><p>So they set up a scheduler and broke down each task into smaller parts.</p><p>The scheduler assigns a specific time for processing each task and then moves to another. Put simply, the CPU runs those micro tasks in an interleaved order.</p><p>The technique of switching between different tasks at once is called .</p><p>But concurrency only creates an illusion of parallel execution. </p><p>The performance worsens when the number of tasks increases. Because each task has to wait for its turn, causing an extra delay.</p><p>So they added extra CPU cores. And each CPU core could run a task independently.</p><p>Think of the  as a processing unit within the CPU; it handles instructions.</p><p>The technique of handling many tasks at once is called  It offers efficiency.</p><p><a href=\"https://coderabbit.link/neo-kim\">CodeRabbit</a> is your AI-powered code review co-pilot. </p><p>It gives you instant, contextual feedback on every PR and one-click fix suggestions. It has reviewed over 10 million PRs and is used in 1 million repositories. </p><p>Besides, it‚Äôs free to use for open-source repos; 70K+ open-source projects already use it.</p><p>CodeRabbit lets you instantly spot:</p><ul><li><p>Security issues (XSS, SQL injection, CSRF)</p></li><li><p>Concurrency problems (deadlocks, race conditions)</p></li><li><p>Code smells &amp; readability concerns</p></li><li><p>Best practice violations (SOLID, DRY, KISS)</p></li><li><p>Weak test coverage &amp; performance bottlenecks</p></li></ul><p>Write clean, secure, and performant code with CodeRabbit.</p><h2>Concurrency Is Not Parallelism</h2><p>Concurrency is about the design, while parallelism is about the execution model.</p><h3>1. Concurrency vs Parallelism</h3><p>Imagine  as a chef making doner kebab for 3 customers. He switches between fries, meat, and vegetables. </p><p>And consider  as 3 chefs making doner kebab for 3 customers; all done at the same time.</p><p>The CPU-intensive tasks run efficiently with parallelism.</p><p>Yet parallelism wastes CPU time when there are I/O heavy tasks.</p><p>Also running tasks on different CPUs doesn‚Äôt always speed them up. Because coordinating tasks for independent execution is necessary.</p><p>So combine concurrency with parallelism to build efficient, scalable, and responsive systems.</p><p>Besides simultaneous changes to the same data might corrupt it.</p><p>Yet it‚Äôs difficult to determine when a thread will get scheduled or which instructions it‚Äôll run.</p><p>So it‚Äôs necessary to use synchronization techniques, such as locking.</p><p>Think of a  as the smallest processing unit scheduled by the operating system.</p><p>A thread must acquire the lock to do a set of operations. While another thread can use the CPU only after the current thread releases the lock.</p><p><em>The 2 popular synchronization primitives are mutex and semaphore</em>. They‚Äôre used to coordinate access to a shared resource.</p><p>A mutex allows only 1 thread to access the shared resource at a time. While semaphore limits the number of threads accessing a shared resource at a time.</p><p>Imagine the  as a single key to enter the building. And think of the  as a bowl of keys to enter a building.</p><p>Besides programming languages, such as <a href=\"https://go.dev/\">Go</a>, allow to build concurrent and parallel solutions without explicit locking mechanisms.</p><p>Here are some use cases of concurrency and parallelism in system design:</p><ul><li><p>A client fetches data via asynchronous callbacks. While main thread handles user input to keep the UI responsive.</p></li><li><p>A load balancer uses non-blocking I/O or a thread pool to avoid connection queuing. </p></li><li><p>A server uses event-driven or multi-threading models to handle requests. Also many servers could be installed for parallelism.</p></li><li><p>A connection pooler allows clients to share a set of database connections. While queries get executed in parallel across those connections.</p></li></ul><p>A sharded database allows clients to make parallel queries and then merge the responses. Besides the client could access and change data at once using database concurrency techniques.</p><p>Concurrency is not parallelism; instead, it‚Äôs a way of structuring tasks to enable parallelism. Thus making it easy to scale.</p><p>One should break down a problem into smaller, independent tasks for concurrency. Then compose the smaller tasks in parallel to solve the problem efficiently.</p><p>Remember, a system in which all tasks run in parallel and stay busy all the time has the maximum throughput.</p><p>Subscribe to get simplified case studies delivered straight to your inbox:</p><p><strong>Want to advertise in this newsletter? </strong>üì∞</p><p>Thank you for supporting this newsletter.</p><p>You are now 154,001+ readers strong, very close to 155k. Let‚Äôs try to get 155k readers by 25 June. Consider sharing this post with your friends and get rewards.</p><p>You can find a summary of this article <a href=\"https://www.linkedin.com/posts/nk-systemdesign-one_most-people-think-concurrency-parallelism-activity-7341068418319589376-ZRCy\">here</a>. Consider a repost if you find it helpful.</p>","contentLength":4993,"flags":null,"enclosureUrl":"https://substack-post-media.s3.amazonaws.com/public/images/0fcfed3a-4c04-4759-b872-33dbfa050c54_1280x720.png","enclosureMime":"","commentsUrl":null},{"title":"Everything You Need to Know About Cache Strategies ‚≠ê","url":"https://newsletter.systemdesign.one/p/cache-strategies","date":1749815530,"author":"Neo Kim","guid":120,"unread":true,"content":"<p>Get my system design playbook for FREE on newsletter signup:</p><p><em>This post outlines popular cache strategies. You will find references at the bottom of this page if you want to go deeper.</em></p><p>Once upon a time, there lived a junior software engineer named Asahi.</p><p>He worked for a tech company named Hooli.</p><p>Although smart, he never received the opportunity to work on any interesting project.</p><p>So he was sad and frustrated.</p><p>Until one day, when he had the idea of applying for a new job.</p><p>And the interviewer asked him 1 simple question,</p><p><em>‚ÄúCan you list 5 popular cache strategies?‚Äù.</em></p><p>Yet he failed to answer it, and the interview was over in 7 minutes.</p><p>So he studied it later to fill the knowledge gap.</p><p><a href=\"https://tiny.outlier.ai/3b3y7fbs\">Outlier</a> is hiring experienced developers to help train cutting-edge AI models with expert human feedback. Work flexibly from anywhere, get paid weekly (up to $50/hr), and apply your real-world dev skills to real AI challenges‚Äîno AI experience required.</p><p>He failed the interview, so you don‚Äôt have to.</p><p>And here‚Äôs how you can answer it:</p><p>A  is used to store frequently accessed data, thus serving future requests faster. Also it keeps data in memory for low latency. Yet the available memory is limited. So frequent updates to the cache are necessary.</p><p>The technique of storing, retrieving, and managing data in a cache for performance and optimal memory usage is called a .</p><p>The cache aside is one of the most popular cache strategies. </p><p>It‚Äôs also called  because data gets cached only when it‚Äôs queried.</p><ol><li><p>The app tries to read data from the cache</p></li><li><p>It then reads data from the database on a cache miss</p></li><li><p>The data gets written to the cache</p></li></ol><p>A  means the queried data is unavailable in the cache.</p><p>Besides the cache doesn't interact with the database directly; instead, the app does.</p><p>This strategy is easy to implement. But there‚Äôs a risk of data inconsistency and extra latency because of network round trips.</p><p>It‚Äôs used in read-heavy workloads, such as configuration data or user profiles.</p><p>Ready for the next technique?</p><h3>2. Write Through Strategy</h3><p>The write-through cache strategy ensures strong consistency between the cache and the database.</p><ol><li><p>The app writes to the cache</p></li><li><p>The cache thenwritesto the database </p></li></ol><p>The app doesn't interact with the database directly; instead, the cache does.</p><p>Although this strategy offers data consistency, the latency on writes is higher. Also the cache space might get wasted with infrequently accessed data.</p><p>It‚Äôs used where write rate is low, and when data freshness is critical.</p><p>The read-through cache strategy installs the cache between the app and the database. This means all reads go through the cache.</p><ol><li><p>The app reads data from the cache</p></li><li><p>Then it reads data from the database on a cache miss</p></li><li><p>The data gets written to the cache and then returned to the app</p></li></ol><p>The app doesn't interact with the database directly; instead, the cache does.</p><p>Although this strategy offers low latency, there‚Äôs a risk of data inconsistency.</p><p>It‚Äôs used in read-heavy workloads, such as a newsfeed or a product catalog.</p><p>The write-back strategy writes data to the cache for batching and performance. This means write latency is low.</p><ol><li><p>The app writes to the cache directly</p></li><li><p>The cache then writes datato the database </p></li></ol><p>This strategy offers better write performance through batching. Yet there‚Äôs a risk of data loss if the cache fails before writing to the database.</p><p>It‚Äôs used in write-heavy workloads where throughput is more important than durability.</p><p>Here‚Äôs how the write-around cache strategy works:</p><ol><li><p>The app writes to the database</p></li><li><p>It tries to read data from the cache later</p></li><li><p>The app reads from the database on a cache miss</p></li><li><p>It then updates the cache</p></li></ol><p>Although this strategy optimizes cache storage for frequently accessed data, there is a risk of increased latency because of cache misses.</p><p>It‚Äôs used for large data objects where updates happen rarely.</p><p>The 2 popular cache implementations are Redis and Memcached.</p><ul><li><p>Read heavy workload: use cache aside or read through strategies</p></li><li><p>Consistency vs throughput: use write-through or write-back strategies</p></li><li><p>Avoid caching one-off writes: use write-around strategy</p></li></ul><p>It‚Äôs important to pick the right cache strategy based on your needs and tradeoffs.</p><p>Subscribe to get simplified case studies delivered straight to your inbox:</p><p><strong>Want to advertise in this newsletter? </strong>üì∞</p><p>Thank you for supporting this newsletter. Consider sharing this post with your friends and get rewards. Y‚Äôall are the best.</p><p>You can find a summary of this article <a href=\"https://www.linkedin.com/posts/nk-systemdesign-one_if-i-had-to-set-up-a-cache-here-are-5-strategies-activity-7339258136458915841-ylOY\">here</a>. Consider a repost if you find it helpful.</p>","contentLength":4460,"flags":null,"enclosureUrl":"https://substack-post-media.s3.amazonaws.com/public/images/10b1dce9-2a0d-432a-9e79-0bb31c53e57a_1280x720.png","enclosureMime":"","commentsUrl":null},{"title":"How API Gateway Actually Work ‚≠ê","url":"https://newsletter.systemdesign.one/p/how-api-gateway-works","date":1748518297,"author":"Neo Kim","guid":119,"unread":true,"content":"<p>Get my system design playbook for FREE on newsletter signup:</p><p><em>This post outlines how API Gateway</em><em>works. You will find references at the bottom of this page if you want to go deeper.</em></p><p>Once upon a time, there lived a software engineering student named Maya.</p><p>She worked as a freelancer part-time.</p><p>Although she had many customers, the platform fee was extremely high.</p><p>One day, she decided to build a freelancer site with fair pricing.</p><p>And her tiny site became popular in a short time.</p><p>So she set up a microservices architecture for scalability.</p><p>Yet she didn‚Äôt know much about architectural design patterns.</p><p>And set up separate public URLs for each microservice.</p><p>The client talked directly to different microservices based on the task.</p><p>This means tight coupling and increased client complexity.</p><p>Also many users accessed her site on their mobile. </p><p>Yet she sent the same amount of information to the desktop and mobile users.</p><p>And this worsened the latency and bandwidth usage.</p><p>So she set up an API Gateway.</p><p>Imagine the  as a hotel receptionist who checks a user‚Äôs reservation and gives them room keys.</p><p>It let her move the non-business logic, such as authorization, into a separate service.</p><p>Code reviews are critical but time-consuming. CodeRabbit acts as your AI co-pilot, giving you instant code review comments and the potential impact of each pull request.</p><p>Besides, CodeRabbit provides one-click fix suggestions. It also lets you define custom code quality rules using AST Grep patterns and catch subtle issues that traditional static analysis tools might miss.</p><p>CodeRabbit has reviewed over 10 million PRs; it's installed on 1 million repositories, and 70k+ open-source projects use it. CodeRabbit is free for all open-source repos.</p><ul><li><p>Logical errors (incorrect conditions, miscalculations)</p></li><li><p>Common pitfalls (off-by-one, infinite loops)</p></li><li><p>Concurrency issues (data races, deadlocks)</p></li><li><p>Security vulnerabilities (SQL injection, XSS, CSRF)</p></li><li><p>Code smells (duplication, lengthy methods)</p></li><li><p>Best practices violations (SOLID, DRY, KISS)</p></li><li><p>Complexity issues (time &amp; space inefficiencies)</p></li><li><p>Weak error handling (especially external calls)</p></li><li><p>Maintainability &amp; readability concerns</p></li></ul><p>Writing clean, secure, and performant code is tough. CodeRabbit makes it easy.</p><p>The API Gateway acts as a single entry point for the site.</p><p>The client sends the request over <a href=\"https://www.cloudflare.com/en-gb/learning/ssl/what-is-https/\">HTTPS</a> for security.</p><p>Yet it has to be decrypted, and this takes extra processing power on each server.</p><p>So the API Gateway does . This means decrypting traffic before forwarding it to microservices, thus reducing server load.</p><p>Here‚Äôs how the API Gateway routes the request:</p><ol><li><p>The client sends the request to the API Gateway</p></li><li><p>It then checks if the client is allowed to make the request</p></li><li><p>The API Gateway validates the request‚Äôs header and body against the schema. Also transform the request if necessary</p></li><li><p>It routes the request to the correct microservices. It handles routing based on the request‚Äôs URL path, HTTP headers, method, or query parameters</p></li><li><p>The API Gateway then combines the responses from different microservices</p></li><li><p>It responds to the client and caches the response for future requests if needed</p></li></ol><p>Also it finds the device type, such as desktop or mobile, from HTTP headers to route the request accordingly. This approach simplifies the client logic and improves latency.</p><p>Besides the API Gateway prevents overloading of unhealthy servers by pausing repeated failing requests. This technique is called the .</p><p>Although the API Gateway simplifies client interactions, it introduces a set of problems.</p><ul><li><p>It increases latency as there‚Äôs an extra network hop</p></li><li><p>It increases costs and operational complexity because of maintenance efforts</p></li><li><p>It might become a performance bottleneck when there‚Äôs high traffic</p></li></ul><p>Also it could become a  if set up incorrectly. So it‚Äôs necessary to install more instances of the API Gateway for high availability.</p><p>Some popular ways to set up an API Gateway are using <a href=\"https://nginx.org/\">Nginx</a>, <a href=\"https://konghq.com/\">Kong</a>, or <a href=\"https://tyk.io/\">Tyk</a>.</p><p>A popular variant of the API Gateway is the backend for frontend () pattern. It means a separate API Gateway for each device type‚Äîdesktop and mobile.</p><p>While the API Gateway pattern offers many benefits, it‚Äôs important to use it carefully. Otherwise it‚Äôll add more complexity than value.</p><p>Subscribe to get simplified case studies delivered straight to your inbox:</p><p><strong>Want to advertise in this newsletter? </strong>üì∞</p><p>Thank you for supporting this newsletter. Consider sharing this post with your friends and get rewards. Y‚Äôall are the best.</p><p>You can find a summary of the article <a href=\"https://www.linkedin.com/posts/nk-systemdesign-one_give-me-2-minsill-teach-you-how-api-gateway-activity-7333816910720999428-mHbA\">here</a>. Consider a repost if you find it helpful.</p>","contentLength":4495,"flags":null,"enclosureUrl":"https://substack-post-media.s3.amazonaws.com/public/images/98649508-84dd-4f6b-872c-d2550b4cc7a5_1280x720.png","enclosureMime":"","commentsUrl":null}],"tags":["dev"]}