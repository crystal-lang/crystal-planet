{"id":"2bP4pJr4wVimh6yine63HqNeafoyheTFz1gqCrQ4h7Z","title":"AlgoMaster Newsletter","displayTitle":"Dev - Algomaster","url":"https://blog.algomaster.io/feed","feedLink":"https://blog.algomaster.io/","isQuery":false,"isEmpty":false,"isHidden":false,"itemCount":5,"items":[{"title":"Designing a Distributed Rate Limiter","url":"https://blog.algomaster.io/p/designing-a-distributed-rate-limiter","date":1749994427,"author":"Ashish Pratap Singh","guid":735,"unread":true,"content":"<p>A  is a mechanism used to <strong>control the number of requests or operations</strong> a user, client, or system can perform <strong>within a specific time window</strong>.</p><p>Its primary purpose is to ensure  of resources, , and  from being overwhelmed by sudden spikes in traffic.</p><blockquote><p> If a system allows a maximum of , any request beyond that limit within the same minute would either be  or , often with an HTTP  response.</p></blockquote><p>In this article, we will dive into the system design of a , and explore the the 5 most commonly used with examples, pros and cons.</p><p>Before diving into the architecture, lets outline the functional and non-functional requirements:</p><h2>1.1 Functional Requirements</h2><ul><li><p>Enforce a fixed number of requests per user or API key within a defined time window (e.g., 100 requests per minute). Excess requests should be rejected with an HTTP .</p></li><li><p>Limits must be enforced consistently across all nodes in a distributed environment. Users shouldn't bypass limits by switching servers.</p></li><li><p>Apply limits across multiple time granularities simultaneously (e.g., per second, per minute, per hour) to prevent abuse over short and long bursts.</p></li></ul><h2>1.2 Non-Functional Requirements</h2><p>To be usable at scale, our distributed rate-limiter must meet several critical non-functional goals:</p><ul><li><p>The system should scale horizontally to handle massive request volumes and growing user counts.</p></li><li><p>Rate limit checks should be fast ideally adding no more than a few milliseconds per request.</p></li><li><p>The rate-limiter should continue working  even under heavy load or node failures. There should be no single point of failure.</p></li><li><p>All nodes should have a  of each user’s request counts. This prevents a client from bypassing limits by routing requests through different servers.</p></li><li><p>The system should support a large number of operations per second and serve many concurrent clients without significant performance degradation.</p></li></ul><p>The  acts as a  between the client and the backend servers. Its job is to inspect incoming requests and enforce predefined usage limits (e.g., 100 requests per minute per user or IP).</p><p>To apply these limits effectively, the rate limiter must  for each client. These counts are often maintained across , such as per second, per minute, or per hour.</p><p>Using a <strong>traditional relational database</strong> for this purpose is generally unsuitable due to:</p><ul><li><p>: Relational databases involve disk I/O, which introduces delays on every read/write.</p></li><li><p>: Handling thousands of concurrent updates (e.g., one per incoming request) can lead to locks and race conditions.</p></li><li><p>: RDBMSs are not optimized for high-frequency, real-time counter updates. </p></li></ul><p>An  like  is a far better fit for rate limiting use cases because it offers:</p><ul><li><p> for both reads and writes</p></li><li><p> like , , and , ensuring safe concurrent updates without race conditions</p></li><li><p><strong>TTL (Time-to-Live) support</strong>, allowing counters to reset automatically at the end of each time window (e.g., after 60 seconds for a per-minute limit)</p></li></ul><p>Here’s how the rate limiter fits into the flow of an incoming request:</p><ol><li><p> to an endpoint of the application.</p></li><li><p>The  performs several checks:</p><ul><li><p>Identifies the client (via IP, token, or API key)</p></li><li><p>Looks up the current request count in Redis (or in-memory cache)</p></li><li><p>Applies any  (e.g., free vs premium users)</p></li></ul></li><li><p>If the count <strong>exceeds the allowed threshold</strong>, the request is  with <code>HTTP 429 Too Many Requests</code>.</p></li><li><p>If the count is , the counter is incremented and the request proceeds to the backend service.</p></li><li><p>Periodically,  via TTL or are reset based on window granularity.</p></li></ol><blockquote><p>Many modern applications delegate rate limiting to  such as  or , which can efficiently enforce limits before traffic reaches backend services. However, for this discussion, we will focus on designing a  that is integrated into or called by  directly.</p></blockquote><h2>3.1 Single-Node Rate Limiting</h2><p>For small-scale applications with <strong>low traffic and a single application server</strong>, rate limiting can be implemented entirely , without relying on external systems like Redis. This approach is lightweight, fast, and easy to set up.</p><p>You maintain a simple  in the application process where:</p><ul><li><p> represent client identifiers (e.g., user ID, API key, or IP address)</p></li><li><p> represent request counts within the current time window</p></li></ul><p>For each incoming request:</p><ol><li><p>Checks if the user exists in the map</p></li><li><p>If not, create a new entry with a count of 1</p></li><li><p>If the user exists, increments their counter</p></li><li><p>Compare the count against the defined rate limit</p></li><li><p>If the count is within the limit, allow the request; otherwise, reject it</p></li></ol><p>You can also add a time-based mechanism (e.g., timestamps or TTL logic) to reset counters after each time window.</p><p>Despite its simplicity, this approach comes with  that make it unsuitable for production environments at scale:</p><ol><li><p><strong>Single Point of Failure (SPOF): </strong>If the server crashes, all in-memory counters are lost. After a restart, the system \"forgets\" users' recent request history potentially allowing them to exceed their limits until the counters rebuild.</p></li><li><p><strong>No Horizontal Scalability: </strong>The rate limiter lives on a so it doesn’t scale with traffic.</p></li><li><p>Without proper eviction or TTL logic, memory usage can grow unbounded over time, especially if you're tracking many users or long-duration windows.</p></li></ol><p>Now, lets explore two common strategies to implement rate limiting in a distributed environment.</p><h2>3.2 Distributed Rate Limiting</h2>","contentLength":5166,"flags":null,"enclosureUrl":"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F92234a57-99c1-41af-9d3c-91a4c045c413_1188x902.png","enclosureMime":"","commentsUrl":null},{"title":"What are JSON Web Tokens (JWTs)?","url":"https://blog.algomaster.io/p/json-web-tokens","date":1749533487,"author":"Ashish Pratap Singh","guid":734,"unread":true,"content":"<p>A  is an open standard for securely authenticating users and sending information between a client (like a web or mobile app) and a server.</p><p>In traditional web applications, user authentication relied on .</p><p>Here’s how it typically worked:</p><ol><li><p>The user logs in with their credentials.</p></li><li><p>The server validates those credentials and creates a session (with session ID).</p></li><li><p>Session data (like user ID and roles) is stored on the server, either in memory or a database.</p></li><li><p>The server sends the session ID to the client .</p></li><li><p>The client stores the session ID locally (usually in a browser cookie).</p></li><li><p>For every subsequent request, the client sends this session ID.</p></li><li><p>The server looks up the session ID to authenticate and authorize the user.</p></li></ol><p>While this approach is simple and effective for small applications, it doesn’t scale well in <strong>distributed systems or microservices architectures</strong> since it requires maintaining shared session state across servers.</p><p> takes a different approach. It stores user claims directly inside the token, which remains on the client. The server only needs to verify the  to authenticate the user, without storing any session data.</p><p>This makes them a great choice for building scalable APIs that do not depend on shared memory or server-side sessions.</p><p>In this article, we'll cover:</p><ul><li><p>What a JWT token looks like?</p></li><li><p>Security considerations and best practices</p></li></ul><p> is offering <strong>flexible, remote freelance opportunities</strong> for frontend developers to help shape the future of AI—<strong>no prior AI experience required</strong>.</p><p>Whether you specialize in <strong>React, Next.js, or modern UI/UX design</strong>, Outlier’s projects let you apply your coding skills to review, evaluate, and improve AI-generated code while earning plus bonuses, with .</p><ul><li><p>💰 : Up to $30/hr (USD) based on expertise &amp; location</p></li><li><p>🌎 : No contracts, fully remote, choose your own hours</p></li><li><p>🧠 : Collaborate on next-gen AI workflows</p></li><li><p>🎯 : No AI background needed—just strong HTML, CSS, JS, React/Vue</p></li></ul><blockquote><p>A  is a compact, URL-safe token used to securely transmit information between two parties, typically a client and a server. </p></blockquote><p>It is digitally signed, ensuring the data inside hasn’t been tampered with and can be trusted. It’s like a  that proves who you are.</p><p>JWTs are widely used in modern web and mobile applications, especially for  and . </p><p>Here's why they're so popular:</p><ul><li><p><strong>Stateless Authentication: </strong>With JWTs, all the necessary user information (like user ID, role, and expiration time) is stored .</p></li><li><p>Because JWTs are , they can be easily used in distributed systems and microservices without the need to share session state across servers.</p></li><li><p>JWTs are signed (and optionally encrypted), ensuring that the data hasn’t been tampered with and can be trusted.</p></li><li><p>JWTs support , which means you can store any data your application needs such as roles, permissions, or tenant IDs.</p></li><li><p> Verifying a signature (especially HMAC) can be faster than making a database call to look up session information.</p></li><li><p><strong>Cross-Domain Communication (CORS):</strong> Since JWTs are typically sent in an HTTP header, they work well across different domains, unlike cookies which have stricter domain policies.</p></li></ul><p>A JSON Web Token (JWT) is made up of , separated by dots:</p><p>Each part serves a specific purpose. Let’s break it down.</p><p>The header contains metadata about the token.</p><p>It usually looks like this:</p><pre><code>{\n  \"alg\": \"HS256\",\n  \"typ\": \"JWT\"\n}</code></pre><ul><li><p>: The algorithm used to sign the token (e.g., HS256 for HMAC, RS256 for RSA).</p></li><li><p>: The token type, always set to \"JWT\".</p></li></ul><p>This JSON is then  to form the  of the token.</p><p>The payload contains the , information about the user or system. Claims are just pieces of data.</p><p>There are three types of claims:</p><p>A set of predefined and commonly used claims. Not required, but recommended.</p><ul><li><p>: Issuer (who issued the token)</p></li><li><p>: Subject (who the token refers to, often the user ID)</p></li><li><p>: Audience (who the token is intended for)</p></li><li><p>: Expiration time (when the token expires)</p></li><li><p>: Not before (token becomes valid after this time)</p></li><li><p>: Issued at (when the token was created)</p></li><li><p>: Token ID (unique identifier to prevent reuse)</p></li></ul><p>These are custom claims that are shared publicly. Should be unique to avoid conflicts, ideally defined in a public namespace.</p><p>These are custom claims created to share information between parties that agree on using them. They are neither registered nor public claims. (e.g., userId, username, roles, permissions).</p><pre><code>{\n  \"sub\": \"1234567890\",\n  \"name\": \"John Doe\",\n  \"admin\": true,\n  \"iat\": 1516239022,\n  \"exp\": 1516242622 // Expires in 1 hour\n}</code></pre><p>This JSON is also  to form the  of the token.</p><blockquote><p>The payload is encoded, not encrypted. Anyone can decode it, so <strong>never put sensitive information like passwords inside</strong>.</p></blockquote><p>This is the security part. It's used to verify that the sender of the JWT is who it says it is and to ensure that the message wasn't changed along the way.</p><ol><li><p>Sign the resulting string using the algorithm mentioned in the header () and a secret or private key</p></li></ol><p>Example using HMAC SHA-256:</p><pre><code>HMACSHA256(\n  base64UrlEncode(header) + \".\" + base64UrlEncode(payload),\n  secret\n)</code></pre><p>The result is  and forms the  of the token.</p><p>Here’s a step-by-step look at how authentication typically works using JWTs:</p><p>The user initiates a login by sending a POST request with their email and password or social login token:</p><pre><code>POST /login\n{\n  \"email\": \"test@example.com\",\n  \"password\": \"mypassword\"\n}</code></pre><h3>Step 2: Server Verifies Credentials &amp; Generates JWT</h3><p>If the credentials are valid, the authentication server generates a JWT:</p><pre><code><code>const token = jwt.sign(\n  { userId: 123, role: 'admin' },\n  SECRET_KEY,\n  { expiresIn: '1h' }\n);</code></code></pre><ul><li><p>The token payload includes user-specific claims, such as user ID and role.</p></li><li><p>The token also contains an expiration time ().</p></li><li><p>The header and payload are signed using a secret key (for HS256) or a private key (for RS256).</p></li></ul><p>The server sends the generated JWT back to the client, typically in the response body.</p><pre><code>{\n  \"token\": \"eyJhbGciOiJIUzI1NiIsInR...\"\n}</code></pre><h3>Step 3: Client Stores JWT</h3><p>The client securely stores the token for use in future requests. Common storage options include:</p><ul><li><p>:  or  (though these are vulnerable to XSS attacks), or preferably an  (which cannot be accessed via JavaScript).</p></li><li><p>: Platform-specific secure storage solutions, such as Keychain on iOS or Keystore on Android.</p></li></ul><h3>Step 4: Client Sends JWT with Each Request</h3><p>For every subsequent API call, the client includes the JWT in the  header using the Bearer schema:</p><pre><code>GET /dashboard\nAuthorization: Bearer &lt;JWT_TOKEN&gt;</code></pre><p>This allows the server to identify and authenticate the user without storing session state.</p><h3>Step 5: Server Verifies Signature and Grants Access</h3><ul><li><p>Extracts the token from the  header</p></li><li><p>Verifies the token’s signature and checks for expiration</p></li></ul><p>If the token is valid, the user is authenticated and the server processes the request.</p><p>If the token is invalid or expired, the server responds with an appropriate error, such as:</p><pre><code>401 Unauthorized\n403 Forbidden</code></pre><p>While JWTs are powerful, incorrect implementation can lead to serious vulnerabilities.</p><p>Here’s how to use them securely:</p><p>Transmit JWTs only over HTTPS to prevent them from being intercepted in transit.</p><h4>Keep Secrets/Private Keys Secure</h4><p>If the secret is leaked, tokens can be forged.</p><ul><li><p>For , use strong, randomly generated secret keys.</p></li></ul><ul><li><p>For , protect the  carefully. Never expose it on the client or in version control.</p></li></ul><h4>Choose Strong Signing Algorithms</h4><ul><li><p>Avoid  at all costs. Some older libraries allowed this, disabling signature checks. Make sure your library  tokens with .</p></li></ul><ul><li><p>Choose strong algorithms like , , or  Avoid older/weaker ones.</p></li></ul><h4>Always Verify the Signature</h4><p>This is the core of JWT security. Never trust a token without validating its signature.</p><p>These claims are essential for ensuring a token is legitimate and appropriate for your service:</p><ul><li><p> – Always set and validate it. Short-lived tokens are generally more secure.</p></li><li><p> – Optional, but if present, should be checked.</p></li><li><p> – Ensure the token was meant for your application.</p></li><li><p> – Confirm the token was issued by a trusted source.</p></li></ul><h4>Don’t Include Sensitive Data in the Payload</h4><p>JWT payloads are <strong>Base64Url-encoded, not encrypted</strong>. Anyone can decode and read them. Never include secrets, passwords, or sensitive personal data.</p><h4>Handle Token Expiration and Revocation</h4><p>JWTs are stateless, which means once issued, they can’t be revoked easily. You must design with that in mind.</p><ul><li><p> – Issue access tokens that expire quickly (e.g., 15 minutes).</p></li><li><p> – Use longer-lived refresh tokens to issue new access tokens. Refresh tokens can be revoked if needed.</p></li><li><p> – Keep a list of revoked tokens or JTIs. This reintroduces server-side state but allows targeted revocation.</p></li><li><p> – Use the  claim to uniquely identify tokens and track their usage (optional and stateful).</p></li></ul><h4>Secure Storage on the Client</h4><ul><li><p><strong>localStorage/sessionStorage</strong> – Easy but vulnerable to .</p></li><li><p> – Safer from XSS, but requires additional care for  protection.</p></li></ul><p><strong>Best practice for web apps: </strong>Use  and <strong>refresh tokens in HttpOnly cookies</strong> to balance security and usability.</p><p>If you found it valuable, hit a like ❤️ and consider subscribing for more such content every week.</p><div data-attrs=\"{&quot;url&quot;:&quot;https://blog.algomaster.io/p/how-i-mastered-data-structures-and-algorithms?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&amp;token=eyJ1c2VyX2lkIjo4MzYwMjc0MywicG9zdF9pZCI6MTQ1NjU1MjUyLCJpYXQiOjE3MjE1MjE3MzEsImV4cCI6MTcyNDExMzczMSwiaXNzIjoicHViLTIyMDIyNjgiLCJzdWIiOiJwb3N0LXJlYWN0aW9uIn0.2cNY811YEugd5iH9XJQhakBzyahGqF7PcATBlFj5J2w&quot;,&quot;text&quot;:&quot;Share&quot;}\" data-component-name=\"CaptionedButtonToDOM\"><div><p>This post is public so feel free to share it.</p></div></div><p> If you’re enjoying this newsletter and want to get even more value, consider becoming a .</p><p>I hope you have a lovely day!</p>","contentLength":9043,"flags":null,"enclosureUrl":"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffbb21bda-da72-4007-a4be-46c5b4f7b31e_1616x1154.png","enclosureMime":"","commentsUrl":null},{"title":"Design a Web Crawler - System Design Interview","url":"https://blog.algomaster.io/p/design-a-web-crawler-system-design-interview","date":1749358563,"author":"Ashish Pratap Singh","guid":733,"unread":true,"content":"<p>A  (also known as a ) is an automated bot that systematically browses the internet, following links from page to page to discover and collect web content.</p><p>Traditionally, web crawlers have been used by  to discover and index web pages. In recent years, they’ve also become essential for training <strong>large language models (LLMs)</strong> by collecting massive amounts of publicly available text data from across the internet.</p><p>At its core, crawling seems simple:</p><ol><li><p>Start with a list of known URLs (called )</p></li></ol><p>However, designing a crawler that can operate at , processing billions or even trillions of pages, is anything but simple. It introduces several complex engineering challenges like:</p><ul><li><p>How do we prioritize which pages to crawl first?</p></li><li><p>How do we ensure we don’t overload the target servers?</p></li><li><p>How do we avoid redundant crawling of the same URL or content?</p></li><li><p>How do we split the work across hundreds or thousands of crawler nodes?</p></li></ul><p>In this article, we’ll walk through the end-to-end design of a <strong>scalable, distributed web crawler</strong>. We’ll start with the requirements, map out the high-level architecture, explore database and storage options, and dive deep into the core components.</p><p>Before we start drawing boxes and arrows, let's define what our crawler needs to do.</p><h3>1.1 Functional Requirements</h3><ol><li><p> Given a URL, the crawler should be able to download the corresponding content.</p></li><li><p> Save the fetched content for downstream use.</p></li><li><p> Parse the HTML to discover hyperlinks and identify new URLs to crawl.</p></li><li><p> Prevent redundant crawling and storage of the same URL or content. Both URL-level and content-level deduplication should be supported.</p></li><li><p> Follow site-specific crawling rules defined in  files, including disallowed paths and crawl delays.</p></li><li><p><strong>Handle Diverse Content Types:</strong> Support HTML as a primary format, but also be capable of recognizing and handling other formats such as PDFs, XML, images, and scripts.</p></li><li><p> Support recrawling of pages based on content volatility. Frequently updated pages should be revisited more often than static ones.</p></li></ol><h3>1.2 Non-Functional Requirements</h3><ol><li><p> The system should scale horizontally to crawl billions of pages across a large number of domains.</p></li><li><p> The crawler should avoid overwhelming target servers by limiting the rate of requests to each domain.</p></li><li><p> The architecture should allow for easy integration of new modules, such as custom parsers, content filters, storage backends, or processing pipelines.</p></li><li><p><strong>Robustness &amp; Fault Tolerance:</strong> The crawler should gracefully handle failures whether it's a bad URL, a timeout, or a crashing worker node without disrupting the overall system.</p></li><li><p> The crawler should maintain high throughput (pages per second), while also minimizing fetch latency.</p></li></ol><blockquote><p>In a real system design interview, you may only be expected to address a subset of these requirements. Focus on what’s relevant to the problem you’re asked to solve, and clarify assumptions early in the discussion.</p></blockquote><h3>2.1 Number of Pages to Crawl</h3><p>Assume we aim to crawl a subset of the web, not the entire internet, but a meaningful slice. This includes pages across blogs, news sites, e-commerce platforms, documentation pages, and forums.</p><ul><li><p><strong>Additional Metadata (headers, timestamps, etc.)</strong>: ~10 KB</p></li></ul><blockquote><p><strong>Total Data Volume = 1 billion pages × 110 KB = ~110 TB</strong></p></blockquote><p>This estimate covers only the raw HTML and metadata. If we store additional data like structured metadata, embedded files, or full-text search indexes, the storage requirements could grow meaningfully.</p><p>Let’s assume we want to complete the crawl in .</p><ul><li><p> = 1 billion / 10 ≈ </p></li><li><p> ≈ 1150 pages/sec</p></li></ul><blockquote><p> 110 KB/page × 1150 pages/sec = ~126 MB/sec</p></blockquote><p>This means our system must be capable of:</p><ul><li><p>Making over <strong>1150 HTTP requests per second</strong></p></li><li><p>Parsing and storing content at the same rate</p></li></ul><p>Every page typically contains several outbound links, many of which are unique. This causes the  (queue of URLs to visit) to grow rapidly. </p><ul><li><p><strong>Average outbound links per page:</strong> 5</p></li><li><p><strong>New links discovered per second = </strong> 1150 (pages per second) * 5 = 5750</p></li></ul><p>The URL Frontier's needs to handle thousands of new URL submissions per second. We’ll need efficient , , and  to handle this at scale.</p>","contentLength":4039,"flags":null,"enclosureUrl":"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4c560e48-2f72-4659-9f69-f4269895b979_2452x1640.png","enclosureMime":"","commentsUrl":null},{"title":"Strong vs. Eventual Consistency","url":"https://blog.algomaster.io/p/strong-vs-eventual-consistency","date":1748924813,"author":"Ashish Pratap Singh","guid":732,"unread":true,"content":"<p>In today’s distributed systems, data is almost never stored in a single place. It’s replicated across , often spread across <strong>data centers around the world</strong> to ensure high availability, fault tolerance, and performance.</p><p>This global distribution enables scalability but it comes with a critical challenge:</p><blockquote><p><strong>How do we ensure every user and system component sees a consistent and accurate view of the data, especially when updates are happening all the time?</strong></p></blockquote><p>This is where  come into play. They define the rules for how and when changes to data become visible across the system.</p><p>Two of the most widely discussed models are:</p><ul><li><p> – where everyone sees the latest value, always.</p></li><li><p> – where updates eventually propagate, but temporary inconsistencies are allowed.</p></li></ul><p>In this article, we'll break down these two models, explore their trade-offs, when to use each, and how to choose the right model depending on your application's goals.</p><h2>What is Data Consistency in Distributed System?</h2><p>In a , consistency is straightforward: when you write data, any subsequent read returns the most recent value. There’s only one copy of the data.</p><p>But in , where data is replicated across multiple nodes (for <strong>availability, fault tolerance, or low latency)</strong>, things become more complex.</p><p>Imagine you write an update to . That change takes time to  to  and . During this , different nodes may temporarily hold  of the same data.</p><p>Consistency Models define the  a system provides about:</p><ul><li><p> an update becomes visible</p></li><li><p> it becomes visible (to which users or replicas)</p></li><li><p> operations are seen across the system</p></li></ul><p>In essence, consistency models answer the question:</p><blockquote><p><strong>“If I write a piece of data, when and under what conditions will others (or even I) see that new value?”</strong></p></blockquote><p> guarantees that once a write is successfully completed, <strong>any read operation from any client or replica will reflect that write or a newer one</strong>. </p><p>This means that the system always returns the most up-to-date value, regardless of where the read is performed.</p><p>It behaves as if there is a <strong>single, globally synchronized copy of the data</strong>, and all operations occur in a clear and consistent global order.</p><p>To achieve strong consistency, the system performs <strong>coordinated communication between replicas</strong> before confirming a write:</p><ol><li><p>A client sends a write request, such as updating a value in the database.</p></li><li><p>The primary node (e.g., Node A) propagates this write to a group of replicas.</p></li><li><p>Each replica (e.g., Node B, Node C) applies the write and sends an acknowledgment.</p></li><li><p>Only after receiving acknowledgments from all (or enough) replicas does the system confirm the write as complete to the client.</p></li><li><p>From that point onward, any read will return the updated value.</p></li></ol><p>This behavior is made possible through  that ensure all replicas agree on the order of operations. Common protocols used include Paxos and Raft.</p><ul><li><p><strong>Simpler Application Logic</strong>: You don’t need to worry about stale data or implementing custom conflict resolution.</p></li><li><p>: Easy to reason about; data reads always reflect the latest confirmed writes.</p></li><li><p>: Ensures the highest level of data integrity and reliability.</p></li></ul><ul><li><p>: Writes (and sometimes reads) may be slower because they require coordination between nodes, often across regions.</p></li><li><p>: During network partitions or node failures, the system may reject requests to preserve consistency (as per the ).</p></li><li><p>: Implementing strong consistency at scale requires sophisticated protocols and distributed coordination mechanisms.</p></li></ul><h3>When to Use Strong Consistency</h3><p>Strong consistency is the right choice when your application needs <strong>immediate correctness and absolute accuracy</strong>. </p><p>It is especially important when inconsistencies could result in lost data, incorrect decisions, or broken trust such as:</p><ul><li><p><strong>Banking and financial systems</strong>: Balances and transactions must always be accurate.</p></li><li><p>: You can’t afford to sell the same item to two people.</p></li><li><p>: Locks must be exclusive and reflect the latest state.</p></li><li><p>: Duplicate IDs must be prevented across replicas.</p></li></ul><p> is a  that guarantees all replicas in a distributed system will <strong>converge to the same value</strong>,  as long as no new updates are made.</p><blockquote><p>If you stop writing to a piece of data, and wait long enough, <strong>everyone will eventually see the same (latest) version of that data.</strong></p></blockquote><p>There’s <strong>no guarantee about how soon</strong> this convergence happens. In the meantime, different replicas may serve  of the data leading to temporary inconsistencies.</p><p>This model is often used in distributed systems where  and  are prioritized over immediate consistency.</p><ol><li><p>A client sends a  to a node, such as updating a data item on Node A.</p></li><li><p>Node A <strong>acknowledges the write immediately</strong>, without waiting for other replicas to be updated.</p></li><li><p>The updated value is <strong>asynchronously propagated</strong> to other replicas, such as Node B and Node C.</p></li><li><p>While this propagation is in progress, <strong>reads from other replicas</strong> may return stale or outdated data.</p></li><li><p>Once all replicas have received and applied the update, the system is .</p></li></ol><p>This replication process allows the system to <strong>stay highly available and responsive</strong>, even in the presence of network partitions or server failures.</p><p>A temporary inconsistency is acceptable in many scenarios, especially when the data being read is <strong>not critical to business correctness</strong> and <strong>a slight delay in consistency does not harm the user experience</strong>.</p><p>Let’s say you're using a social media platform and you update your profile picture.</p><ul><li><p>You immediately see the new photo on your profile.</p></li><li><p>A friend on the other side of the world might still see your old photo for a few seconds due to .</p></li><li><p>After the system finishes syncing, everyone sees the updated photo.</p></li></ul><p>This temporary inconsistency is acceptable because <strong>the correctness of the system doesn't depend on everyone seeing the same thing at the exact same moment</strong>.</p><ul><li><p>: Writes don’t need to wait for global coordination; responses are fast.</p></li><li><p>: Nodes can accept reads and writes independently even during network partitions.</p></li><li><p>: Ideal for large-scale, globally distributed systems that need to stay responsive under heavy load.</p></li></ul><ul><li><p>Clients may read outdated data until replicas are fully synchronized.</p></li><li><p><strong>Increased Application Complexity</strong>: Developers must handle inconsistency in code especially in read-after-write scenarios.</p></li><li><p>: If multiple replicas accept concurrent writes, you need a conflict resolution strategy (e.g., Last Write Wins, CRDTs).</p></li></ul><h3>When to Use Eventual Consistency</h3><p>Eventual consistency is a good fit for <strong>applications that require high availability and can tolerate temporary inconsistencies</strong>. It is especially effective when systems are distributed globally or need to operate at massive scale.</p><p>Common use cases include:</p><ul><li><p> Like counts, shares, and view counters can tolerate brief inconsistencies without impacting user experience.</p></li><li><p><strong>Product view counts or analytics: </strong>Tracking page visits, clicks, or user events can tolerate minor delays in consistency.</p></li><li><p>Personalized suggestions such as products, movies, or articles do not require real-time accuracy and benefit from fast, large-scale reads.</p></li><li><p><strong>DNS (Domain Name System): </strong>DNS records are cached at multiple layers worldwide. Slight delays in propagation are acceptable and help maintain global availability.</p></li><li><p><strong>Content delivery networks (CDNs): </strong>Static assets like images, stylesheets, and scripts are served from edge locations. Updates propagate gradually to balance performance and consistency.</p></li><li><p> Eventual consistency is suitable when users add items from different devices. Conflict resolution strategies (such as merging or last-write-wins) help maintain a coherent experience.</p></li></ul><h2>Variations and Client-Centric Models</h2><p>It's important to note that \"eventual consistency\" is a broad term. There are stronger forms of eventual consistency that provide better guarantees:</p><ul><li><p> If operation A causally precedes operation B (e.g., B reads a value written by A), then all processes see A before B. Operations that are not causally related can be seen in different orders.</p><ul><li><p>In a comment thread, replies should appear after the comment they respond to even if the system is eventually consistent overall.</p></li></ul></li><li><p><strong>Read-Your-Writes Consistency:</strong> After a client performs a write, any subsequent reads by that same client will always reflect the write (or a newer version). Other clients may still see stale data.</p><ul><li><p>You update your profile bio. When you refresh the page, your new bio appears immediately even if it takes a few seconds for others to see it.</p></li></ul></li><li><p><strong>Monotonic Reads Consistency:</strong> If a client reads a value, any future reads by the same client will return the same or a newer value. The client will never see an older version of the data.</p><ul><li><p>You see your post has 10 likes. After refreshing, you might see 10 or 11 likes but never fewer than 10.</p></li></ul></li><li><p><strong>Monotonic Writes Consistency:</strong> Writes from the same client are executed in the order they were issued by that client.</p><ul><li><p>You post two comments: “Hello” followed by “World.” Other users will always see “Hello” before “World.”</p></li></ul></li></ul><p>Even in an <strong>eventually consistent system</strong>, applying <strong>client-centric guarantees</strong> helps preserve a sense of order, responsiveness, and trust for individual users.</p><h2>Choosing the Right Consistency Model</h2><p>There's no \"best\" consistency model. The right choice depends heavily on your application's specific requirements:</p><p><strong>How critical is it that all users see the most up-to-date, correct data at all times?</strong></p><ul><li><p>High (e.g., financial transactions, inventory management)</p></li><li><p>Lower (e.g., social likes, view counts, analytics)</p><p>→ <strong>Eventual consistency is often sufficient.</strong></p></li></ul><h4>2. User Experience Expectations:</h4><p><strong>Will users notice or care about stale data? Can the UI manage it gracefully?</strong></p><p>For systems where users expect immediate feedback, you can often use:</p><ul><li><p> updates (e.g., show the change immediately, then sync)</p></li><li><p> (e.g., “Syncing…” or “Updating…”)</p></li></ul><p> reduces confusion, but  can be acceptable with the right UX design.</p><h4>3. Performance (Latency) Requirements</h4><p><strong>How important is low latency for reads and writes?</strong></p><ul><li><p> often delivers , since writes don’t block on global coordination.</p></li><li><p> adds overhead especially in geo-distributed systems.</p></li></ul><h4>4. Availability Requirements</h4><p><strong>Can the system tolerate downtime or errors during network partitions?</strong></p><ul><li><p> may sacrifice  to preserve correctness (as per the <a href=\"https://blog.algomaster.io/p/cap-theorem-explained\">CAP theorem</a>).</p></li><li><p> allows systems to  even during partial failures or network splits.</p></li></ul><p><strong>Does the system need to support massive scale across regions or data centers?</strong></p><ul><li><p><strong>Eventually consistent systems</strong> scale more easily especially for .</p></li><li><p> may limit scaling options due to coordination overhead.</p></li></ul><h4>6. Development Complexity</h4><p><strong>How much complexity are you willing to handle at the application layer?</strong></p><ul><li><p> simplifies application logic. Developers can assume they’re always reading the latest state.</p></li><li><p> requires handling: stale data, idempotent operations and conflict resolution.</p></li></ul><p><strong>What happens if two users write conflicting data at the same time?</strong></p><p>In <strong>eventually consistent systems</strong>, concurrent writes to different replicas must be reconciled when replicas sync.</p><ul><li><p>CRDTs (Conflict-Free Replicated Data Types)</p></li><li><p>Custom merge logic based on application semantics</p></li></ul><p>If you found it valuable, hit a like ❤️ and consider subscribing for more such content every week.</p><p>If you have any questions or suggestions, leave a comment.</p><div data-attrs=\"{&quot;url&quot;:&quot;https://blog.algomaster.io/p/strong-vs-eventual-consistency?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;}\" data-component-name=\"CaptionedButtonToDOM\"><div><p>This post is public so feel free to share it.</p></div></div><p> If you’re enjoying this newsletter and want to get even more value, consider becoming a .</p><p>I hope you have a lovely day!</p>","contentLength":11141,"flags":null,"enclosureUrl":"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0fee02cd-828c-4f69-8184-401751cf819c_2070x1398.png","enclosureMime":"","commentsUrl":null},{"title":"Top 10 WebSocket Use Cases in System Design","url":"https://blog.algomaster.io/p/websocket-use-cases-system-design","date":1748524411,"author":"Ashish Pratap Singh","guid":731,"unread":true,"content":"<p>Real-time features are everywhere—chat apps, live dashboards, collaborative editors, multiplayer games. Behind the scenes, one technology powers these seamless interactions: .</p><p>Unlike traditional request-response models, WebSockets enable <strong>full-duplex, low-latency communication</strong> over a single persistent connection. This makes them the ideal choice when both the client and server need to exchange data continuously and without delay.</p><p>In this article, we’ll explore the <strong>top 10 real-world use cases of WebSockets</strong>, many of which are also relevant for .</p><blockquote><p> Each use case includes a simplified system design overview. To stay focused on WebSockets, we'll cover only the components involved in enabling real-time features rather than the full end-to-end system.</p></blockquote><p>In real-time chat applications, users expect —whether it's new messages, typing indicators, delivery receipts, or presence status.</p><p>But delivering this seamless experience at scale is , especially with  and <strong>thousands of concurrent group chats</strong>.</p><p> the server every few seconds to check for new messages isn’t efficient due to: </p><ul><li><p>Wasted bandwidth when no new data is available</p></li><li><p>Server overload, as every client repeatedly hits the backend</p></li></ul><p> solve this by maintaining a <strong>persistent, full-duplex connection</strong> between client and server, enabling:</p><ul><li><p>Real-time typing and presence updates</p></li><li><p>A single connection for sending and receiving, eliminating repeated HTTP overhead</p></li></ul><ul><li><p>: Maintains persistent connections with clients, handles incoming events and messages, and delivers real-time updates to users.</p></li><li><p>: Keeps track of active WebSocket sessions and maps users to their current connections.</p></li><li><p>: Temporarily buffers incoming messages for asynchronous processing, enabling system decoupling and ensuring reliable persistence.</p></li><li><p>: Consumes messages from the queue, attaches relevant metadata, and stores them in the message database.</p></li><li><p>: A durable and scalable database that holds all messages, metadata, and conversation history.</p></li></ul><h4>1. Client Establishes WebSocket Connection</h4><p>When a user opens the app:</p><ul><li><p>The client authenticates with the backend using a </p></li><li><p>Then establishes a  to a chat server:</p><pre><code>{\n  \"action\": \"connect\",\n  \"userId\": \"user-123\",\n  \"device\": \"ios\"\n}</code></pre></li><li><p>This connection remains open for the entire session</p></li></ul><p>When the user sends a message:</p><ul><li><p>The client sends it over the WebSocket connection:</p><pre><code>{\n  \"type\": \"message\",\n  \"conversationId\": \"conv-456\",\n  \"from\": \"user-123\",\n  \"to\": \"user-789\",\n  \"text\": \"Hey! How’s it going?\",\n  \"timestamp\": 1716601000\n}</code></pre></li><li><ul><li><p>Pushes it to a </p></li></ul></li></ul><ul><li><p>The chat server checks the  to find active WebSocket sessions</p></li><li><p>If the user is online, the message is pushed instantly:</p><pre><code>{\n  \"type\": \"incoming_message\",\n  \"conversationId\": \"conv-456\",\n  \"from\": \"user-123\",\n  \"text\": \"Hey! How’s it going?\",\n  \"timestamp\": 1716601000\n}</code></pre></li></ul><ul><li><ul><li><p>The message is stored for delivery upon reconnect</p></li><li><p>Or sent as a </p></li></ul></li></ul><p>The <strong>same WebSocket connection</strong> used for messaging can also be leveraged to send  like typing indicators and presence status.</p><p>When a user begins typing in a conversation:</p><ul><li><p>The client sends a lightweight event over the open WebSocket connection:</p><pre><code>{\n  \"type\": \"typing\",\n  \"conversationId\": \"conv-456\",\n  \"userId\": \"user-123\"\n}</code></pre></li><li><p>The server receives the event and checks the  to determine if the recipient(s) are currently online.</p></li><li><p>If they are online, the typing event is  to their active WebSocket sessions.</p></li><li><p>If they are offline, the event is discarded (not stored), since it's ephemeral and has no long-term value.</p></li></ul><p>Typing events are typically throttled (e.g., once every few seconds) to avoid flooding the system.</p><p>In fast-paced online multiplayer games, <strong>every millisecond matters. </strong></p><ul><li><p> across all players</p></li></ul><p>If you rely on HTTP polling where clients keep asking the server for updates, you introduce:</p><ul><li><p>: Updates arrive late.</p></li><li><p>: One player sees a different state than another.</p></li><li><p>: Too many requests = stressed servers.</p></li></ul><p> allow game clients and servers to send frequent updates (player positions, moves, game events) in both directions. This keeps all players’ views in sync during gameplay.</p><ul><li><p>Maintain persistent, low-latency connections with players to send and receive real-time game events.</p></li><li><p>Tracks which players are connected, which match they belong to, and which WebSocket server is managing their session.</p></li><li><p>Runs the core game logic including input processing, physics, and rules. Ensures a consistent, authoritative game state.</p></li><li><p>Holds the live, up-to-date snapshot of all game entities (e.g., players, objects, projectiles) for a specific match, updated on every game tick.</p></li></ul><p>Each active game instance (e.g., match, room, arena) is represented as a  identified by a session ID.</p><ul></ul><h4>2. Client Input Streaming</h4><ul><li><p>The client establishes a <strong>persistent WebSocket connection</strong> to one of the WebSocket servers.</p></li><li><p>Sends a  message with its  and session info:</p><pre><code>{\n  \"action\": \"join\",\n  \"playerId\": \"p789\",\n  \"session\": \"arena:1234\"\n}</code></pre></li><li><p>From that point on, the client <strong>streams user input events</strong> (movement, actions, abilities) every :</p><pre><code>{\n  \"type\": \"input\",\n  \"playerId\": \"p789\",\n  \"input\": {\n    \"moveX\": 1,\n    \"moveY\": 0,\n    \"shoot\": true\n  },\n  \"timestamp\": 1716600000\n}</code></pre></li></ul><p>This approach ensures the server receives a continuous stream of player actions in real-time.</p><h4>3. Game Match Server and State Propagation</h4><p>Each session is managed by an <strong>authoritative Game Match Server</strong> that runs a  at a fixed tick rate—typically .</p><p><strong>On each tick, the server:</strong></p><ul><li><p>Collects and queues all input events received from connected players</p></li><li><p>Processes core game logic, including:</p><ul><li><p>Movement and velocity updates</p></li><li><p>Health and damage calculations</p></li></ul></li><li><p>Applies physics and collision detection</p></li><li><p>Updates the in-memory game state</p></li><li><p>Computes a  and sends it to all WebSocket servers managing players in that session:</p><pre><code>{\n  \"type\": \"stateUpdate\",\n  \"tick\": 1441,\n  \"players\": [\n    { \"id\": \"p789\", \"x\": 55, \"y\": 89, \"health\": 92 },\n    { \"id\": \"p231\", \"x\": 52, \"y\": 91, \"health\": 80 }\n  ],\n  \"bullets\": [...],\n  \"timestamp\": 1716600012\n}</code></pre></li></ul><p>WebSocket nodes forward these updates to the connected clients.</p><p>Clients use these updates to  and .</p><p>With efficient engineering practices such as:</p><ul><li><p> and  (e.g., Node.js, Netty)</p></li><li><p> (e.g., quadtrees or grid-based zoning) to broadcast updates only to nearby players</p></li><li><p> to reduce payload size</p></li></ul><p>...a single WebSocket server can support <strong>thousands of concurrent players</strong> across multiple game sessions with .</p><p>On modern social media platforms, users expect to see <strong>new posts, likes, comments, and alerts the moment they happen</strong>.</p><p>But without a real-time mechanism, the client must constantly <strong>poll the server every few seconds</strong> to check for updates. This results in:</p><ul><li><p>High latency for the user (delayed updates)</p></li><li><p>Unnecessary load on servers and wasted bandwidth</p></li></ul><p> enable servers to push these updates instantaneously to connected clients, creating a live feed experience.</p><p>To support <strong>millions of concurrent users</strong>, platforms implement:</p><ul><li><p><strong>Dedicated WebSocket Servers</strong> to manage persistent connections</p></li><li><p> via load balancers (ensuring a user reconnects to the same server)</p></li></ul><ul><li><p><strong>Event Source (Like/Comment): </strong>Captures user interactions (e.g., likes, comments, follows) and generates structured events.</p></li><li><p>Buffers and routes events asynchronously to downstream services for processing (e.g., Kafka, Redis Streams).</p></li><li><p>Consumes events from the queue, determines target users, and routes updates to the appropriate WebSocket servers.</p></li><li><p>Maintain persistent client connections and deliver real-time feed updates to online users.</p></li><li><p>Tracks which users are connected and maps them to their corresponding WebSocket server nodes.</p></li></ul><p>Each user is assigned a <strong>dedicated feed and notification channel</strong>, enabling personalized real-time updates.</p><ul><li><p> – main activity feed</p></li><li><p> – direct notifications (likes, comments, follows)</p></li></ul><p>The system may also support <strong>shared or topic-based channels</strong>:</p><ul><li><p> – AI-related posts</p></li><li><p> – tech hashtag activity</p></li><li><p> – group or community feed</p></li></ul><h4>2. WebSocket Connection &amp; Subscription Flow</h4><p>When a user opens the app:</p><ul><li><p>The client establishes a  to the WebSocket Gateway.</p></li><li><p>After authentication, it sends a  message to specify its feed channels:</p><pre><code>{\n  \"action\": \"subscribe\",\n  \"channels\": [\n    \"feed:user:alice\",\n    \"notifications:user:alice\"\n  ]\n}</code></pre></li><li><p>The WebSocket server registers these channel subscriptions in a , typically in an in-memory registry or <strong>a distributed cache (e.g., Redis).</strong></p></li></ul><h4>3. Event Generation &amp; Push</h4><p>When a new event occurs such as a comment on a user’s post:</p><ul><li><p>The backend service (e.g., ) emits the event:</p><pre><code>{\n  \"event\": \"new_comment\",\n  \"postId\": \"abc123\",\n  \"commentId\": \"xyz789\",\n  \"byUser\": \"alice\",\n  \"toUser\": \"bob\"\n}</code></pre></li></ul><ul><li><p>The event is <strong>published to a message broker</strong> (e.g., Kafka, Redis Pub/Sub).</p></li><li><p>The Event broadcaster service  and:</p><ul><li><p>Looks up the WebSocket server holding the user’s connection</p></li><li><p>Routes the event to that server, which pushes it to the correct client over the live WebSocket connection</p></li></ul></li></ul><p>The client receives the message and updates the UI immediately (e.g., displaying a toast notification or updating the comment count in real time).</p>","contentLength":8764,"flags":null,"enclosureUrl":"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5634c993-d806-4857-881d-59efe68fb5e7_1616x1432.png","enclosureMime":"","commentsUrl":null}],"tags":["dev"]}